---
layout: page
title: Research
published: true
css: /css/cherie.css
---
<style>
    img.responsive-img {
    width: 800px;
    max-width: 100%; /* Ensures it doesnâ€™t exceed its container */
    display: block; /* Centers the image in its container */
    margin: 0 auto; /* Centers the image */
    }

    @media (max-width: 768px) { /* Adjust breakpoint for mobile devices */
        img.responsive-img {
            width: 90%;
    }
}

</style>
## Research Vision
<p align="center">
    <img src="/img/vision_pull.jpg" class="responsive-img" >
</p>
I aim to develop **robots that can continuously learn in new scenarios** to break the need of immense human engineering when encountering new situations and environments. This will pave the way for robots capable of operating effectively and at scale in diverse scenarios. However, robot deployments are not only challenging and costly but also high-stakes, where minor failures can have serious consequences. My vision is to create robots capable of autonomously curating high-quality data safely and at scale while learning efficiently from this data. To achieve this, I propose that robots need to reason about **uncertainty** and **consequences** within a **modular** architecture, allowing them to learn in a risk-adjusted manner when facing new situations. It will continuously learn by identifying knowledge gaps and actively gathering information.

See the full list of my publication [here](publications).

### PhD Thesis: Towards Flexible Robot Perception
<p align="center">
    <img src="/img/research_depth.jpg" class="responsive-img" >
</p>
Toward this goal, my PhD research has laid a foundation by developing perception modules designed for generalizability, adaptability, and enabling proactive exploration in areas of uncertainty.
<br>
<br>
**Generalizable Perception:** My first research focus is the development of generalizable perception modules that exhibit effective zero-shot performance across diverse settings [[NeurIPS'24](https://mapitanywhere.github.io/)]. 
<br><br>
**Adaptive Perception:** While more generalizable perception provides a solid foundation, there is a strong need for real-time adaptability. In this direction, my second line of work explores how a perception module can learn and improve using newly collected data, enhancing its performance over time [[IROS'24](https://arxiv.org/abs/2306.15226), [ICRA'25b\*](https://theairlab.org/SALON)]
<br><br>
**Uncertainty-Aware Perception:** My third area of research examines how a continuously learning agent can assess uncertainty to identify where it should gather information or avoid [[ICRA'25a\*](https://arxiv.org/abs/2409.15590), [ICRA'25b\*](https://theairlab.org/SALON)].


### Robotics Breadth
<p align="center">
    <img src="/img/research_breadth.jpg" class="responsive-img" >
</p>
Robotics systems require development across the full stack. Towards this, my research covers: **Perception** [[NeurIPS'24](https://mapitanywhere.github.io/),
    [IROS'24](https://arxiv.org/abs/2306.15226),
    [ICRA'25a\*](https://arxiv.org/abs/2409.15590), [ICRA'25b\*](https://theairlab.org/SALON),
    [ICRA'25c\*](https://arxiv.org/abs/2403.11876)], **Planning** [
    [IROS'21](https://theairlab.org/multidrone/),
    [JFR'19](https://theairlab.org/drone-filming/),
    [IROS'19](https://arxiv.org/abs/1904.02319)
    ], **Control** [
    [RSS WSA'20a](https://arxiv.org/abs/2110.03119),
    [RSS WSA'20b](https://github.com/hocherie/cbf_quadrotor)
    ].

### Research Applications
<p align="center">
    <img src="/img/research_applications.jpg" class="responsive-img" >
</p>
My research has also spanned multiple applications. Some of the applications are: 
<br>
* Offroad + Urban Navigation: [[NeurIPS'24](https://mapitanywhere.github.io/),
    [IROS'24](https://arxiv.org/abs/2306.15226),[ICRA'25b\*](https://theairlab.org/SALON),
    [ICRA'25c\*](https://arxiv.org/abs/2403.11876)]
<br>
* Drone Cinematography:
[
    [IROS'21](https://theairlab.org/multidrone/),
    [JFR'19](https://theairlab.org/drone-filming/),
    [IROS'19](https://arxiv.org/abs/1904.02319)
]
<br>
* Indoor Exploration:
[
    [ICRA'25a\*](https://arxiv.org/abs/2409.15590)
]

### Research Platforms
<p align="center">
    <img src="/img/research_platforms.jpg" class="responsive-img" >
</p>
A key aspect of my work is getting out there to collect data and working with robots. Towards this, here are some robot platforms I have worked with:
<br>
* Full-Scale Offroad ATVs (Robot Names: Vicky, CMU4, CMU7): [[NeurIPS'24](https://mapitanywhere.github.io/),
    [IROS'24](https://arxiv.org/abs/2306.15226),[ICRA'25b\*](https://theairlab.org/SALON),
    [ICRA'25c\*](https://arxiv.org/abs/2403.11876)]
<br>
* Quadcopters (Robot Names: Mia, M1, M2, M3, M4):
[
    [IROS'21](https://theairlab.org/multidrone/),
    [JFR'19](https://theairlab.org/drone-filming/),
    [IROS'19](https://arxiv.org/abs/1904.02319)
]
<br>
* Urban Wheelchair (Robot Name: wheelie):
[
    [ICRA'25a\*](https://arxiv.org/abs/2409.15590)
]
